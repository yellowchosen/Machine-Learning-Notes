<img width="802" alt="Screen Shot 2022-07-13 at 11 58 30 PM" src="https://user-images.githubusercontent.com/99445916/178895319-c9c89245-5244-4b09-96b1-7bc988dbd3ef.png">



# Cost Function
In multiple linear regression, its cost function should be very similiar with simple linear regression:
$$J(w_0, w_1,..., w_n,b) = \frac{1}{2m}\sum_{i=1}^{m}(f_{w,b}(x^{(i)}) - y^{(i)})$$ and we define $f_{w, b}(x) = w^Tx$


# Compare these two types of gradient descent
<img width="805" alt="Screen Shot 2022-07-14 at 12 25 07 AM" src="https://user-images.githubusercontent.com/99445916/178898317-411cf3bf-0d54-41f7-804d-18c1153bc424.png">
